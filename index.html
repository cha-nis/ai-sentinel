<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>AI Sentinel</title>
    <meta name="description" content="Figma htmlGenerator">
    <meta name="author" content="htmlGenerator">
    <link href="https://fonts.googleapis.com/css?family=Inter&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Notable&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div class="header-fixed">
        <div class="header-content">
          <div class="e665_55" onclick="scrollToTop()">></div>
            <span class="e665_51"><a href="#overview">개요</a></span>
            <span class="e665_52"><a href="#ai_regulatory">국가별 AI 법안</a></span>
            <span class="e665_53"><a href="#bill_comparison">법안 비교</a></span>
            <span class="e665_54"><a href="#improvements">법안 개선점</a></span>
          
            
        </div>
    </div>
    <div class="e665_49">
        <div class="e672_262"></div>
        <div class="e665_50"></div>
        <div class="e665_59"></div>
        <span class="e665_68" id="overview">Overview</span>
        <span class="e665_88">
            AI 기술의 급속한 발전은 다양한 산업에 혁신을 가져오는 동시에 윤리적, 안전성 문제를 야기하고 있다. 
            한국은 이러한 도전에 대응하기 위해 AI 규제 법안을 마련하고자 하며,
             이를 위해 여러 개선 과제를 극복해야 한다. 
             위 내용을 토대로 한국에서 AI 규제 법안을 마련하기 위해 필요한 개선점과 극복 과제를 작성했다.<br><br><br><br>
            1. 자율 규제 <br>
            한국은 AI 기술 개발의 자유를 보장하는 자율 규제를 지향해야 한다. 
            이를 통해 개발자들이 창의적이고 혁신적인 AI 기술을 자유롭게 개발할 수 있도록 지원해야 한다. 
            자율 규제는 정부의 개입을 최소화하여 빠른 기술 발전을 유도할 수 있다.<br><br>
            2. 혁신 촉진 <br>
            규제 샌드박스를 도입하여 혁신적인 AI 기술 개발을 촉진해야 한다. 
            이를 통해 새로운 기술을 실험하고 평가할 수 있는 환경을 제공함으로써, 
            안전성과 윤리성을 검증하면서도 빠른 발전을 지원할 수 있다.<br><br>
            3. 정부 지원 <br>
            정부는 AI 기술 발전을 위한 연구와 지원 프로그램에 집중해야 한다. 
            이를 통해 AI 기술의 발전을 촉진하고, 기업들이 안정적으로 연구개발을 할 수 있도록 돕는다. 
            정부의 지원은 특히 초기 단계의 스타트업과 같은 소규모 기업들에게 큰 도움이 될 것이다.<br><br>
            4. 범용 규제 <br>
            특정 기술에 국한되지 않고 범용적이고 유연한 규제 프레임워크를 적용해야 한다. 
            이는 다양한 AI 기술의 발전을 저해하지 않으면서도 기본적인 안전성과 윤리적 기준을 유지할 수 있게 한다.<br><br>
            5. 국제 협력 <br>
            강조 글로벌 AI 규제 프레임워크 수립을 위한 국제적 협력과 표준화 노력을 강화해야 한다. 
            이를 통해 한국의 AI 기술이 글로벌 시장에서 경쟁력을 갖출 수 있도록 하고,
             국제적인 규제 회피의 위험을 최소화할 수 있다.<br><br><br><br>
            한국은 AI 규제 법안을 마련함에 있어 자율 규제, 혁신 촉진, 정부 지원, 범용 규제, 
            국제 협력 강조 등의 방안을 통해 기술 발전과 안전성을 균형 있게 관리해야 한다. 
            이러한 과제를 성공적으로 극복함으로써 한국은 AI 기술의 안전하고 윤리적인 발전을 촉진하는 규제 프레임워크를 구축할 수 있을 것이다. 
            이는 AI 기술의 사회적 수용성을 높이고, 글로벌 시장에서의 경쟁력을 강화하는 데 기여할 것이다.
        </span>
        <span class="e665_78" id="improvements">Improvements <br>to the bill</span>
        <span class="e665_87">
            AI 규제에 있어서 전 세계적으로 여러 관점이 존재하지만, 
            특정한 핵심 원칙들을 중심으로 일련의 공통점을 찾을 수 있음. 
            공통된 6가지 규제 동향은<br><br>
            ▲ 인권존중, 지속가능성, 투명성 및 강력한 위험관리 등과 같은 핵심 원칙 고려 <br>
            ▲위험기반 접근 방식<br>
            ▲다양한 업종별 맞춤 규제<br>
            ▲다양한 정책과의 조정<br>
            ▲ 민간 부문 협력 <br>
            ▲ 국제적 협력으로 이루어짐.<br><br>
            정책 입안자들은 규제기관이 위와 같은 정책을 성공적으로 시행, 
            감독 및 집행할 수 있도록 관련 전문 지식에 대한 충분한 접근을 보장하는지 고려해야 함. 
            또한 규정 준수 의무가 기술 자체에서 발생하는 위험 또는 AI 기술의 사용 방법 또는 둘 다 규제하려고 하는 경우와, 
            위험 관리 정책 및 절차와 AI 관련 제품/서비스를 공급하는 제 3자 벤더에 대한 규정 준수 책임을 
            어디까지 적용할 것인지 검토가 필요함. 
            이렇듯 정책 입안자들은 가능한 한 다자간 과정에 참여하여 AI 규칙을 국가 간에 상호 운용 가능하고 비교가능하게 만들어,
             AI와같은 초국가적 기술의 사용을 규율하는 규칙을 마련할 때 특히 중요한 규제회피에 관련된 위험을 최소화 해야 함.
        </span>
        <span class="e665_85">common ground</span>
        <span class="e665_102">
            유럽연합 (EU)<br>
            1. 사전 승인 및 인증: AI 시스템 개발 전에 엄격한 규제를 받음.<br>
            2. 위험 분류: AI 시스템을 위험 수준에 따라 분류하고 고위험 시스템에 대한 엄격한 감독과 규제 적용.<br>
            3. 사용 제한: 특정 AI 애플리케이션 사용 금지.<br>
            4. 투명성 및 데이터 관리: 투명성과 데이터 관리 의무 강조.<br>
            5. 강화된 안전 기준: AI 시스템의 안전성과 윤리적 사용 보장.<br><br>
            중국<br>
            1. 사전 승인 및 인증: AI 서비스 등록 및 보안 심사 의무화.<br>
            2. 위험 분류: AI 기술의 위험성을 평가하고 규제 적용.<br>
            3. 사용 제한: 특정 AI 애플리케이션에 대한 엄격한 규제.<br>
            4. 투명성 및 데이터 관리: 합법적 데이터 소스 사용 및 사용자 프라이버시 보호.<br>
            5. 강화된 안전 기준: 기술의 안전성과 윤리적 사용 강조.<br>
        </span>
        <span class="e665_104">
            사전 승인 및 인증: AI 시스템 개발 전에 정부 또는 규제 기관의 사전 승인과 인증을 필요로 한다.
            위험 분류: AI 시스템을 위험 수준에 따라 분류하고, 고위험 AI에 대한 엄격한 감독과 규제 적용.
            사용 제한: 특정 AI 기술 또는 애플리케이션의 사용을 금지하거나 제한.
            투명성 및 데이터 관리: AI 시스템의 투명성 확보 및 데이터 관리 의무를 강조.
            강화된 안전 기준: AI 시스템의 안전성과 윤리적 사용을 보장하기 위한 강화된 기준 적용.
        </span>
        <span class="e665_99">strict regulatory approach</span>
        <span class="e665_103">
            미국<br>
            1. 자율 규제: 연방 법안 대신 개별 기관이 자율적으로 규제.<br>
            2. 혁신 촉진: 규제 샌드박스를 통해 혁신적 AI 기술 개발 촉진.<br>
            3. 정부 지원: 연구 및 지원 프로그램을 통해 AI 기술 발전 촉진.<br>
            4. 범용 규제: 특정 기술보다는 범용적이고 유연한 규제 프레임워크 적용.<br>
            5. 국제 협력 강조: 글로벌 AI 규제 프레임워크 수립을 위한 국제적 협력 강화.<br><br>
            한국<br>
            1. 자율 규제: AI 기술 개발의 자유를 보장.<br>
            2. 혁신 촉진: 혁신적 AI 기술 개발을 위한 다양한 지원 정책.<br>
            3. 정부 지원: AI 기술 발전을 위한 정책 로드맵 마련.<br>
            4. 범용 규제: 유연한 규제 프레임워크 적용.<br>
            5. 국제 협력 강조: 국제적 협력과 표준화 노력 강화.
        </span>
        <span class="e665_101">
            자율 규제: 개발자가 자율적으로 AI 기술을 개발하고 관리, 정부의 개입 최소화.
            혁신 촉진: 규제 샌드박스를 통해 혁신적 AI 기술 개발을 촉진, 빠른 기술 발전 유도.
            정부 지원: 정부는 규제보다는 AI 기술 발전을 위한 연구와 지원 프로그램에 집중.
            범용 규제: 특정 기술보다는 범용적이고 유연한 규제 프레임워크 적용.
            국제 협력 강조: 글로벌 AI 규제 프레임워크 수립을 위한 국제적 협력과 표준화 노력 강화.
        </span>
        <span class="e665_100">liberal regulatory approach</span>
        <span class="e665_77" id="bill_comparison">bill comparison</span>
        <span class="e665_90">
            영국은 2023년 11월 1일 제1회 AI 안전성 정상회의(AI Safety Summit) 에서 
            ‘블레츨리 선언 (Bletchley Declaration)’을 발표함. 
            블레츨리 선언은 AI 안전과 윤리에 대한 글로벌 약속으로, 
            29개의 서명국은 안전하고 인간 중심적이며 윤리 원칙에 부합하는 AI 기술 개발을 위해 협력하기로 함. 
            AI의 도전과 기회를 해결하기 위한 국제 협력의 중요성을 강조하며, 
            전 세계적으로 안전하고 유익한 AI 기술 개발을 위한 협력적인 방향을 제시함. 
            AI 안전성 정상회의에서 제시된 5가지 목표는 다음과 같음. <br><br>
            1. 프론티어 AI가 초래하는 위험과 조치의 필요성에 대한 이해 공유<br>
            2. 국내 및 국제 프레임워크를 지원하는 최선의 방법을 포함하여 프론티어 AI 안전에 대한 <br>국제협력을 위한 전진 프로세스<br>
            3. 개별 조직이 프론티어 AI 안전을 강화하기 위해 취해야 할 적절한 조치<br>
            4. 모델 기능 평가 및 거버넌스를 지원하기 위한 새로운 표준 개발을 포함하여 <br>AI 안전연구에 대한 잠재적 협력분야 발굴<br>
            5. AI의 안전한 개발을 보장함으로써 AI가 전세계적으로 정직하게 사용될 수 있는 방법 제시
        </span>
        <span class="e665_95">UNITED KINGDOM</span>
        <div class="e673_265"></div>
        <div class="e673_267"></div>
        <span class="e665_92">
            일본자민당
            2024년내 AI법안도입추진 일본 자유민주당(Liberal Democratic Party)은 
            2024년 내에 AI 법안을 도입할 계획을 발표함. 법안은 허위 정보를 걸러내고, 
            저작권을 보호하며, AI의 윤리적 사용을 보장하는 데 중점을 둠. 
            일본은 AI에 대한 법적 틀을 마련함으로써 기술혁신을 촉진하고 사회적 가치와 개인의 권리를 보호하고자 함.<br><br> 
            일본,AI연구소설립 <br>
            일본은 2024년 2월 14일 경제산업성 산하에 AI 안전 연구소를 설립함. 연구소는 AI 기술과 관련된 리스크에 대한 대응이 국제적인 과제로 떠오른 가운데, 이를 완화하기 위한 일본의 정부의 의지를 강조하며, 국제 파트너와 협력하여AI의 안전표준,평가 방법론 및우수사례를개발함으로써AI의 책임있는사용을보장하기 위한 글로벌 노력에 기여할 예정임.
        </span>
        <span class="e665_91">JAPAN</span>
        <span class="e665_89">
            조 바이든(Joe Biden) 대통령은 2023년 10월 30일 미국 최초의 AI 관련 행정 명령을 발표함. 행정 명령은
            ▲AI 안전 및 보안을 위한 새로운 표준 ▲국민의 개인 정보 보호 ▲형평성 및 시민권 증진 ▲소비자, 환자 및
            학생을 위한 AI, ▲근로자 지원 ▲혁신과 경쟁 촉진 ▲전 세계적 AI 리더십 발전 ▲책임감 있고 효과적인 정부의
            AI 사용 보장과같은 조치를 포함하고 있음.<br>
            미국 행정부는 국내에서 AI 관련 의제를 추진하는 동시에, 해외 동맹국 및 파트너들과 함께 AI 개발 및 사용을
            관리하기 위한 국제적 프레임워크 수립을 위해 협력할 것을 발표함. 
            현재 호주, 브라질, 캐나다, 칠레, 유럽연합, 프랑스, 독일, 인도, 이스라엘, 이탈리아, 일본, 케냐, 멕시코, 네덜란드, 신규 국가 등 다양한 국가와 교류함.<br>
            이번 AI 관련 행정 명령은 일본의 G-7 히로시마 프로세스, 영국의 AI 안전 관련 정상회담, 인도가 주도하는 글로벌 파트너십 인공지능 의장국으로서의 
            리더십, 그리고 유엔에서 진행중인 논의를 지원하고 보완하고 있음. <br>
            조 바이든 대통령이 지시한 AI 행정 명령은 AI 분야에서 혁신을 촉진하고, 시민의 자유를 보호하며, 국가 안보를 유지하기 위한 전략적 접근을 개괄함. 
            더불어 윤리적이고 책임감 있으며 민주적 가치와 일치하는 AI 기술의 개발을 강조하며, 잠재적인 사회적 영향을 해결하면서 미국이 AI 발전의 최전선에 있도록 함.
            미국 백악관은 2023년 7월 21일, AI 기업을 대상으로 ‘AI 안전 서약’을 발표함. 서약에는 기업들이 생성형 AI
            콘텐츠에 워터마크를 포함하는 등 AI를 책임있고 안전하게 사용할 것을 약속하는 8개 조항이 포함되어 있음.
            8개 조항으로는 
            ▲제품을 대중에게 소개하기 전 안전성 보장 
            ▲보안을 최우선으로 하는 시스템을 구축 
            ▲워터마크와 같이 AI로 생성된 창착물임을 알 수 있도록 신뢰를 보장한 콘텐츠 개발 및 배포 등의 내용을 담고 있음. <br>
            자발적인 AI 안전 서약은 업계 리더들이 AI 개발 및 배포에서 안전, 보안, 투명성을 우선시하도록 장려함.
            서약에 참여하는 기업들은 AI 시스템의 안전조치에 대한 엄격한 테스트, 위험 평가 및 공개 보고에 동의함. 오픈AI, 구글, 마이크로소프트, 아마존, 메타, 엔트로픽, 인플렉션 AI 등 대형언어모델(LLM)을 보유한 주요 기업들이 해당 서약에 동의한 것으로 알려짐. 이 이니셔티브는 AI 기술이 사회에 이익을 주면서 위험을 최소화하도록정부와 민간 부문 간의 협력 노력을 반영함.
        </span>
        <span class="e665_94">United States of America</span>
        <div class="e673_266"></div>
        <div class="e673_264"></div>
        <span class="e665_86">
            2023년 10월 25일, 유럽연합은 인공지능법(AI Act)에 대한 최종 합의에 도달함. <br>
            약 2년간의 협상 끝에 이루어진 결정적인 진전으로, 현재 EU는 인공지능법의 세부 사항을 최종 확정하기
            위한 삼국회담 절차로 넘어감. 이는 AI에 대한 포괄적인 규제 프레임워크를 수립하며, AI 시스템을 위험 
            수준에 따라 분류하고,고위험 애플리케이션에대해 엄격한 요구사항을부과하게됨을 의미함.<br>
            EU 인공지능법의 핵심 요소 중 하나는 ‘고위험’ AI 시스템의 식별과 감독 강화임. 이를 통해 AI의 신뢰성을
            보장하고 기본권을 보호하며, 디지털 단일 시장 내에서 혁신을 촉진하는 것을 목표로 함. 또한, AI 시스템의
            위험 수준에 따라 의무를 부과하며, 시민의 권리와 민주주의에 위협이 되는 특정 애플리케이션의 사용을
            금지함. 특히, 생체 인식 분류 시스템과 얼굴 인식 데이터베이스에 대한 비표적 스크래핑 등을 금지하는 내
            용을 담고 있음. 더불어 범용 AI 시스템에 대한 투명성 요구 사항을 설정하고, 혁신 및 중소기업(SMEs)을
            지원하기 위한 조치 또한 도입함.<br>
            이러한 법안은 투명성, 데이터 거버넌스 및 책임감에 대한 의무를 도입하여 AI 규제에 대한 글로벌 기준을
            설정함. 준수하지 않을 경우에는 상당한 벌금이 부과될 수 있으며, 이를 통해 AI의 안전한 운영 및 기본권 
            존중, 그리고 혁신 촉진을 목표로 함. 이러한 동향은 앞으로 AI 기술에 대한 국제적인 규제 흐름에 중요한
            영향을 미칠 것으로 예상됨.
        </span>
        <span class="e665_84">European Union</span>
        <span class="e665_76" id="ai_regulatory">ai regulatory bill</span>
        <span class="e665_93">
            AI 기술의 급속한 발전은 윤리적 및 안보적인 문제가 잇따른다. 
            이 사이트는 한국, 유럽연합, 미국, 중국 일본 등 주요 국가의 AI 규제 법안과 동향울 비교하고, 
            각국의 규제 접근법을 분석한다. 각국의 규제 방식을 통해 엄격한 규제와 자유로운 규제의 차이를 이해하고, 
            공통점과 차이덤을 바탕으로 효과적인 AI 규제 방안을 모색한다.<br><br>
            주요 내용<br><br>
            1. 공통점: 투명성, 윤리적 기준, 안정성 확보, 혁신 촉진, 국제 협력<br>
            2. 차이점: 규제 접근, 정부 역할, 규제 범위, 산업 표준화, 혁신 지원 방식<br>
            3. 국가별 접근법: 한국 유럽연합, 미국, 중국, 일본 등<br>
        </span>
    </div>
    <script src="script.js"></script>
  </script>
</body>
</html>
